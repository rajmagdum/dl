{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb299d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2391842",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a1. Direct Text Given then uncomment below line and Comment entire a2 till b (for PS:15)\n",
    "\n",
    "# corpus = [\"The speed of transmission is an important point of difference between the two viruses. Influenza has a shorter median incubation period (the time from infection to appearance of symptoms) and a shorter serial interval (the time between successive cases) than COVID-19 virus. The serial interval for COVID-19 virus is estimated to be 5-6 days, while for influenza virus, the serial interval is 3 days. This means that influenza can spread faster than COVID-19. Further, transmission in the first 3-5 days of illness, or potentially pre-symptomatic transmission –transmission of the virus before the appearance of symptoms – is a major driver of transmission for influenza. In contrast, while we are learning that there are people who can shed COVID-19 virus 24-48 hours prior to symptom onset, at present, this does not appear to be a major driver of transmission. The reproductive number – the number of secondary infections generated from one infected individual – is understood to be between 2 and 2.5 for COVID-19 virus, higher than for influenza. However, estimates for both COVID-19 and influenza viruses are very context and time-specific, making direct comparisons more difficult.\"]\n",
    "\n",
    "# a2. Read the corpus from a file and comment entire a1 till a2 (for PS:6 7 8)\n",
    "corpus = []\n",
    "with open(\"input.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        corpus.append(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71587f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. Generate training data (CBOW representation)\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(corpus)\n",
    "X, y = [], []\n",
    "\n",
    "for seq in sequences:\n",
    "    for i, target_word in enumerate(seq):\n",
    "        for j in range(max(0, i - 2), min(i + 3, len(seq))):\n",
    "            if i != j:\n",
    "                X.append([target_word, seq[j]])\n",
    "                y.append(1)  # Positive context\n",
    "                X.append([target_word, np.random.choice(list(word_index.values()))])\n",
    "                y.append(0)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c212b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 2, 1)              103       \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 1)                0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 105\n",
      "Trainable params: 105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# c. Train model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(word_index) + 1, output_dim=1, input_length=2),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=100, verbose=0)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbfad294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: [-0.37010488]\n",
      "of: [-0.48188525]\n",
      "influenza: [-0.46069774]\n",
      "covid: [-0.45239773]\n",
      "19: [-0.27636144]\n",
      "virus: [-0.32765952]\n",
      "for: [-0.48407477]\n",
      "transmission: [-0.2200723]\n",
      "is: [-0.40631753]\n",
      "to: [-0.5447663]\n",
      "a: [-0.35021117]\n",
      "and: [-0.1916189]\n",
      "between: [-0.01801419]\n",
      "time: [-0.35303912]\n",
      "serial: [-0.23205838]\n",
      "interval: [-0.06594086]\n",
      "than: [-0.04720962]\n",
      "be: [0.00748012]\n",
      "5: [-0.15831295]\n",
      "days: [-0.2052238]\n",
      "â€“: [-0.16303705]\n",
      "are: [-0.4490381]\n",
      "viruses: [-0.09630861]\n",
      "shorter: [-0.11520135]\n",
      "from: [0.03738713]\n",
      "appearance: [-0.09285238]\n",
      "symptoms: [-0.00954651]\n",
      "while: [0.02118974]\n",
      "3: [-0.20101418]\n",
      "this: [-0.16127083]\n",
      "that: [0.04334296]\n",
      "can: [-0.11270068]\n",
      "in: [-0.03438266]\n",
      "major: [-0.05847953]\n",
      "driver: [0.04912895]\n",
      "number: [0.10532448]\n",
      "2: [-0.14720155]\n",
      "speed: [-0.0617995]\n",
      "an: [0.21000293]\n",
      "important: [0.385957]\n",
      "point: [0.17243873]\n",
      "difference: [-0.22974]\n",
      "two: [0.05333519]\n",
      "has: [-0.2054785]\n",
      "median: [0.16456467]\n",
      "incubation: [0.43703637]\n",
      "period: [0.4987716]\n",
      "infection: [0.1893826]\n",
      "successive: [0.30351338]\n",
      "cases: [0.15138714]\n",
      "estimated: [0.28998727]\n",
      "6: [0.11514968]\n",
      "means: [0.2048022]\n",
      "spread: [0.40180922]\n",
      "faster: [0.3109789]\n",
      "further: [0.5253272]\n",
      "first: [0.15777631]\n",
      "illness: [0.21276604]\n",
      "or: [0.06164526]\n",
      "potentially: [-0.22483985]\n",
      "pre: [0.36426473]\n",
      "symptomatic: [0.17772752]\n",
      "â€“transmission: [0.26342922]\n",
      "before: [0.10134412]\n",
      "contrast: [0.01180796]\n",
      "we: [0.07264105]\n",
      "learning: [-0.08652204]\n",
      "there: [0.23181716]\n",
      "people: [0.47786844]\n",
      "who: [0.39658296]\n",
      "shed: [0.26868415]\n",
      "24: [0.4293648]\n",
      "48: [-0.24881534]\n",
      "hours: [0.49147812]\n",
      "prior: [0.2965442]\n",
      "symptom: [0.3620606]\n",
      "onset: [-0.05835233]\n",
      "at: [-0.08773196]\n",
      "present: [0.3703205]\n",
      "does: [-0.20848948]\n",
      "not: [0.4974969]\n",
      "appear: [0.07119197]\n",
      "reproductive: [0.13159835]\n",
      "secondary: [0.332832]\n",
      "infections: [0.21295103]\n",
      "generated: [-0.12502725]\n",
      "one: [0.44280258]\n",
      "infected: [0.03794884]\n",
      "individual: [0.36765066]\n",
      "understood: [0.21112418]\n",
      "higher: [0.58737814]\n",
      "however: [0.3598712]\n",
      "estimates: [-0.00649448]\n",
      "both: [0.34492528]\n",
      "very: [0.40476322]\n",
      "context: [0.19061609]\n",
      "specific: [0.2778874]\n",
      "making: [0.07397272]\n",
      "direct: [0.3532004]\n",
      "comparisons: [0.20920512]\n",
      "more: [0.48552468]\n",
      "difficult: [0.8491088]\n"
     ]
    }
   ],
   "source": [
    "# d. Output\n",
    "word_embeddings = model.layers[0].get_weights()[0]\n",
    "for word, index in word_index.items():\n",
    "    print(f\"{word}: {word_embeddings[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "333b0cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'viruses': ['5', 'days', 'are', 'onset']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "target_word = 'viruses'\n",
    "target_embedding = word_embeddings[tokenizer.word_index[target_word]]\n",
    "\n",
    "similarities = cosine_similarity(target_embedding.reshape(1, -1), word_embeddings)[0]\n",
    "most_similar_indices = similarities.argsort()[-5:][::-1]\n",
    "    \n",
    "most_similar_words = [word for word, idx in tokenizer.word_index.items() if idx in most_similar_indices]\n",
    "\n",
    "print(f\"Most similar words to '{target_word}': {most_similar_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a9cc91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
